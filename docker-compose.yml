version: '1'
services:
  mtebservice:
    build:
      context: .
      dockerfile: PythonGPU.Dockerfile
      shm_size: '2gb' # shared memory size when building
    shm_size: '2gb' # shared memory size when running
    container_name: amanda_memoreba
    runtime: nvidia
    volumes: 
      - ./code:/traducao-amanda-container/code-container
      - NVIDIA_VISIBLE_DEVICES=all
    environment:
      - PIP_NO_CACHE_DIR=1
# Para o computador do CEIA: Limitações de CPU e reserva de GPU
    deploy:
      resources:
        limits:
          memory: 31G
          cpus: "8.0"
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["3"] # especificar aqui o ID da GPU
              capabilities: ["gpu"]
